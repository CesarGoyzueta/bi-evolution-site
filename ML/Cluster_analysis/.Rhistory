# H0: la serie es i.i.d.
m_vals <- c(2, 3, 4)
for (m in m_vals) {
cat(sprintf("\n-- BDS con m = %d --\n", m))
bd <- bds.test(as.numeric(rend), m = m)
print(bd)
# InterpretaciÃ³n rÃ¡pida:
# p-value alto  -> NO rechazo H0 -> rendimientos compatibles con i.i.d.
# p-value bajo  -> rechazo H0     -> hay dependencia/no linealidad
}
#==============================================#
# 5) Test BDS de independencia (rendimientos)
#==============================================#
#install.packages("tseries")   # solo la 1Âª vez
library(tseries)              # SIEMPRE en la sesiÃ³n donde vas a usar bds.test
cat("\n[5] TEST BDS (i.i.d.)\n")
sd_r <- sd(rend)
cat(sprintf("sd(r) = %.6f\n", sd_r))
# Embedding dimension m (comÃºn: 8â€“10). Usamos 8.
# bds.test() a veces falla con m muy grande o series cortas,
# asÃ­ que probamos varias dimensiones (m) tÃ­picas: 2, 3 y 4.
# H0: la serie es i.i.d.
m_vals <- c(2, 3, 4)
for (m in m_vals) {
cat(sprintf("\n-- BDS con m = %d --\n", m))
bd <- bds.test(as.numeric(rend), m = m)
print(bd)
# InterpretaciÃ³n rÃ¡pida:
# p-value alto  -> NO rechazo H0 -> rendimientos compatibles con i.i.d.
# p-value bajo  -> rechazo H0     -> hay dependencia/no linealidad
}
#==============================================#
cat("\n[6] NORMALIDAD (bandas y densidades)\n")
# Limpieza mÃ­nima por si acaso
r_clean <- as.numeric(rend)
r_clean <- r_clean[is.finite(r_clean)]
# Media y desviaciÃ³n
m_r <- mean(r_clean); s_r <- sd(r_clean)
# Ãndices fuera de Â±2Ïƒ
idx_out <- which(abs(r_clean - m_r) > 2*s_r)
n_out   <- length(idx_out)
n_tot   <- length(r_clean)
pct_out <- 100 * n_out / n_tot
# Referencia teÃ³rica bajo N(0,1): ~4.55% fuera de Â±2Ïƒ
pct_theo <- 100 * (2 * (1 - pnorm(2)))  # â‰ˆ 4.55%
cat(sprintf("Puntos fuera de Â±2Ïƒ: %d / %d  (%.4f%%)\n", n_out, n_tot, pct_out))
cat(sprintf("Referencia teÃ³rica N(0,1): %.2f%% fuera de Â±2Ïƒ\n", pct_theo))
# ---- GrÃ¡fico de la serie con bandas y puntos fuera de Â±2Ïƒ destacados ----
png("figs/06_rend_bandas_2sigma.png", width = 1100, height = 460)
dev.off()
# ---- GrÃ¡fico de la serie con bandas y puntos fuera de Â±2Ïƒ destacados ----
#png("figs/06_rend_bandas_2sigma.png", width = 1100, height = 460)
plot(r_clean, type="l",
main = expression(paste("Rendimientos con bandas  ", "\u00B1","2",sigma)),
xlab = "Tiempo", ylab = expression(r[t]))
abline(h = m_r, lty = 3)
abline(h = m_r + 2*s_r, lty = 2, col = "red")
abline(h = m_r - 2*s_r, lty = 2, col = "red")
# Puntos fuera de Â±2Ïƒ
if (n_out > 0) points(idx_out, r_clean[idx_out], col = "red", pch = 19)
legend("topleft", bty = "n",
legend = c(
sprintf("Fuera Â±2Ïƒ: %d / %d (%.2f%%)", n_out, n_tot, pct_out),
sprintf("TeÃ³rico N(0,1): %.2f%%", pct_theo)
))
# Referencia teÃ³rica bajo N(0,1): ~4.55% fuera de Â±2Ïƒ
pct_theo <- 100 * (2 * (1 - pnorm(2)))  # â‰ˆ 4.55%
cat(sprintf("Puntos fuera de Â±2Ïƒ: %d / %d  (%.4f%%)\n", n_out, n_tot, pct_out))
cat(sprintf("Referencia teÃ³rica N(0,1): %.2f%% fuera de Â±2Ïƒ\n", pct_theo))
# ---- Estandarizar rendimientos para comparar con N(0,1) ----
z <- (r_clean - m_r) / s_r
#png("figs/06_hist_dens_normal.png", width = 1100, height = 460)
hist(z, breaks = "FD", freq = FALSE,
main = sprintf("z = (r - media)/sd | EmpÃ­rico vs N(0,1)\nFuera Â±2Ïƒ: %.2f%% (TeÃ³rico: %.2f%%)",
pct_out, pct_theo),
xlab = "z", ylab = "Densidad")
lines(density(z), lwd = 2)                 # densidad empÃ­rica
curve(dnorm(x, 0, 1), add = TRUE, lwd = 2, lty = 2)  # N(0,1) teÃ³rica
legend("topright", bty = "n",
legend = c("Densidad empÃ­rica", "N(0,1)"),
lty = c(1, 2), lwd = c(2, 2))
# Paquetes (aÃ±ado pracma para Hurst sin source externos)
if(!require(pracma)) install.packages("pracma")
library(pracma)
#==============================================#
# 2) ACF/PACF de rendimientos + Ljungâ€“Box para p = 1,2,3,4,5
#   (versiÃ³n robusta: limpia NAs/Inf antes de los tests)
#==============================================#
#
# â€¢ ACF(r): mira si los rendimientos estÃ¡n correlacionados con sus rezagos.
# - H0 (Ljungâ€“Box): no hay autocorrelaciÃ³n conjunta hasta el lag k.
# - Si los p-valores son bajos â†’ hay dependencia en media â†’ modelo ARMA tiene sentido.
#
# â€¢ PACF(r): igual que ACF pero â€œlimpiaâ€ el efecto de rezagos intermedios.
# - Picos en PACF â†’ orden AR.
# - Picos en ACF â†’ orden MA.
#
# â€¢ ACF(rÂ²): se aplica sobre los rendimientos al cuadrado.
# - Sirve para ver SI LA VARIANZA ESTÃ CORRELACIONADA EN EL TIEMPO.
# - Si hay picos en ACF(rÂ²) â†’ hay clustering de volatilidad â†’ despuÃ©s se justifica GARCH.
cat("\n[2] ACF/PACF y Ljung-Box (rendimientos)\n")
# --- Limpieza mÃ­nima por si hubiera NA/NaN/Inf en rend ---
r_clean <- as.numeric(rend)          # asegura vector numÃ©rico
r_clean <- r_clean[is.finite(r_clean)]  # elimina NA, NaN, +Inf, -Inf
# --- GrÃ¡fico ACF/PACF de rendimientos ---
dir.create("figs", showWarnings = FALSE)
#png("figs/02_ACF_PACF_rend.png", width = 1100, height = 500)
par(mfrow = c(1, 2))
Acf(r_clean, lag.max = 40, ylim = c(-0.05, 0.05), main = "ACF(r)",  na.action = na.omit)
library(tseries)
library(zoo)
library(outliers)
library(forecast)
# --- Limpieza mÃ­nima por si hubiera NA/NaN/Inf en rend ---
r_clean <- as.numeric(rend)          # asegura vector numÃ©rico
r_clean <- r_clean[is.finite(r_clean)]  # elimina NA, NaN, +Inf, -Inf
# --- GrÃ¡fico ACF/PACF de rendimientos ---
dir.create("figs", showWarnings = FALSE)
#png("figs/02_ACF_PACF_rend.png", width = 1100, height = 500)
par(mfrow = c(1, 2))
Acf(r_clean, lag.max = 40, ylim = c(-0.05, 0.05), main = "ACF(r)",  na.action = na.omit)
Pacf(r_clean, lag.max = 40, ylim =c(-0.05, 0.05), main = "PACF(r)", na.action = na.omit)
par(mfrow = c(1, 1))
#| include: false
# ============================================================================
# CONFIGURACIÃ“N INICIAL Y CARGA DE LIBRERÃAS
# ============================================================================
#
# EXCEPCIÃ“N: Lo correrÃ­as antes si:
#
# ðŸ”´ Drawdown >-10% (alerta crÃ­tica)
# ðŸ”´ Volatilidad >30% (pÃ¡nico de mercado)
# ðŸ“° Evento mayor (crisis, guerra, Fed inesperado)
# ðŸ“Š RESUMEN ULTRA-CORTO
# Â¿QuÃ©?Â¿CuÃ¡ndo?Â¿Para quÃ©?Ejecutar scriptCada 3 mesesActualizar allocaciÃ³nHTML generadoAl ejecutarLeer anÃ¡lisis completoCSV trading_weightsAl ejecutarComprar acciones en brokerOtros CSVsAl ejecutarGuardar histÃ³rico (opcional)
# Configurar mirror de CRAN
options(repos = c(CRAN = "https://cran.rstudio.com/"))
# Instalar TODOS los paquetes necesarios (solo una vez)
install.packages(c(
"quantmod", "PerformanceAnalytics", "PortfolioAnalytics",
"dplyr", "tidyr", "purrr", "ROI", "ROI.plugin.quadprog",
"ROI.plugin.glpk", "MASS", "ggplot2", "plotly", "patchwork",
"scales", "RColorBrewer", "kableExtra", "DT", "xts", "zoo",
"tseries", "forecast", "lubridate", "jsonlite"
))
# Si no hay errores, estÃ¡s listo âœ“
# LibrerÃ­as principales
library(quantmod)
library(PerformanceAnalytics)
library(PortfolioAnalytics)
library(dplyr)
library(tidyr)
library(purrr)
# OptimizaciÃ³n
library(ROI)
library(ROI.plugin.quadprog)
library(ROI.plugin.glpk)
library(MASS)
# VisualizaciÃ³n
library(ggplot2)
library(plotly)
library(patchwork)
library(scales)
library(RColorBrewer)
# Tablas y reportes
library(kableExtra)
library(DT)
# Series de tiempo
library(xts)
library(zoo)
library(tseries)
library(forecast)
# Utilidades
library(lubridate)
library(jsonlite)
# ConfiguraciÃ³n global
Sys.setenv(TZ = 'UTC')
options(
scipen = 999,
digits = 4,
warn = -1
)
# Colores profesionales
colors_portfolio <- c(
primary = "#2C3E50",
success = "#27AE60",
danger = "#E74C3C",
warning = "#F39C12",
info = "#3498DB",
tech = "#9B59B6",
finance = "#1ABC9C"
)
# ConfiguraciÃ³n de logging
log_file <- paste0("portfolio_log_", format(Sys.Date(), "%Y%m%d"), ".txt")
log_message <- function(msg, level = "INFO") {
timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
log_entry <- sprintf("[%s] %s: %s\n", timestamp, level, msg)
cat(log_entry)
cat(log_entry, file = log_file, append = TRUE)
}
log_message("Iniciando anÃ¡lisis de portfolio profesional")
setwd("C:/Users/Cesar/OneDrive/Proyectos futuros/BI_Evolution/ML/Cluster_analysis")
# Instalar paquetes SOLO la primera vez, despuÃ©s puedes comentarlo
# install.packages(c("readr", "dplyr", "clValid", "cluster", "factoextra", "dbscan", "tibble"))
library(readr)
library(dplyr)
library(clValid)
library(cluster)
library(factoextra)
library(dbscan)
install.packages(c("readr", "dplyr", "clValid", "cluster", "factoextra", "dbscan", "tibble"))
install.packages(c("readr", "dplyr", "clValid", "cluster", "factoextra", "dbscan", "tibble"))
# Instalar paquetes SOLO la primera vez, despuÃ©s puedes comentarlo
# install.packages(c("readr", "dplyr", "clValid", "cluster", "factoextra", "dbscan", "tibble"))
library(readr)
library(dplyr)
library(clValid)
library(cluster)
library(factoextra)
library(dbscan)
library(tibble)
set.seed(123)
prospectos <- read_csv("prospectos_1000.csv")
prospectos <- read_csv("prospectos.csv")
prospectos <- read_csv("prospectos.csv")
setwd("C:/Users/Cesar/OneDrive/Proyectos futuros/BI_Evolution/ML/Cluster_analysis")
prospectos <- read_csv("prospectos.csv")
read_csv("prospectos.csv")
read_csv("prospectos.csv")
prospectos <- read_csv("C:\Users\Cesar\OneDrive\Proyectos futuros\BI_Evolution\ML\Cluster_analysis\prospectos.csv")
prospectos <- read_csv("C:/Users/Cesar/OneDrive/Proyectos futuros/BI_Evolution/ML/Cluster_analysis/prospectos.csv")
glimpse(prospectos)
vars_num <- c(
"edad",
"ingresos_mensuales",
"nivel_interes",
"tiempo_respuesta_min",
"interacciones_previas",
"visitas_web",
"open_rate",
"email_score",
"tiempo_decision_dias"
)
X <- prospectos[, vars_num]
# Escalado (muy importante para clustering basado en distancia)
X_scaled <- scale(X)
summary(X_scaled)
metodos <- c("kmeans", "clara", "hierarchical","fanny")
stab_res <- clValid(
obj        = X_scaled,
nClust     = 2:8,
clMethods  = metodos,
validation = c("stability", "internal"),
maxitems   = 1500
)
# Resumen general (incluye estabilidad + Ã­ndices internos)
summary(stab_res)
metodos <- c("kmeans", "clara", "hierarchical", "fanny")
stab_only <- clValid(
obj        = X_scaled,
nClust     = 2:8,
clMethods  = metodos,
validation = "stability",
maxitems   = 1500
)
# Resumen general de estabilidad (APN, AD, ADM, FOM)
summary(stab_only)
# Extraer las mÃ©tricas de estabilidad
stab_measures <- slot(stab_only, "measures")
# clValid devuelve un array [mÃ©todo, mÃ©trica, k]. Lo reordenamos a tabla larga.
met_names    <- dimnames(stab_measures)[[1]]
metric_names <- dimnames(stab_measures)[[2]]
k_values     <- as.numeric(dimnames(stab_measures)[[3]])
rows <- list()
for (m in seq_along(met_names)) {
for (k in seq_along(k_values)) {
vals <- stab_measures[m, , k]
rows[[length(rows) + 1]] <- c(
metodo = met_names[m],
k      = k_values[k],
APN    = vals["APN"],
AD     = vals["AD"],
ADM    = vals["ADM"],
FOM    = vals["FOM"]
)
}
}
stab_df <- bind_rows(lapply(rows, as_tibble))
stab_df
# Ejemplo: ver las 10 combinaciones mÃ¡s estables segÃºn FOM
stab_df %>%
mutate(
APN = as.numeric(APN),
AD  = as.numeric(AD),
ADM = as.numeric(ADM),
FOM = as.numeric(FOM)
) %>%
arrange(FOM) %>%
head(10)
slot(stab_only, "measures")
k_values
stab_measures
met_names
metric_names
as.numeric(dimnames(stab_measures)[[3]])
dimnames(stab_measures)
stab_measures
# Extraer las mÃ©tricas de estabilidad
stab_measures <- slot(stab_only, "measures")
# Pasar el array [mÃ©todo, mÃ©trica, k] a data.frame largo
stab_df <- as.data.frame.table(stab_measures, responseName = "Score")
# Renombrar columnas para que sean mÃ¡s claras
colnames(stab_df) <- c("Method", "Measure", "Clusters", "Score")
# Aseguramos que 'Clusters' sea numÃ©rico
stab_df$Clusters <- as.numeric(as.character(stab_df$Clusters))
stab_df
stab_df
stab_measures
# Extraer las mÃ©tricas de estabilidad
stab_measures <- slot(stab_only, "measures")
# Pasar el array [mÃ©todo, mÃ©trica, k] a data.frame largo
stab_df <- as.data.frame.table(stab_measures, responseName = "Score")
# Renombrar columnas para que sean mÃ¡s claras
colnames(stab_df) <- c("Method", "Measure", "Clusters", "Score")
# Aseguramos que 'Clusters' sea numÃ©rico
stab_df$Clusters <- as.numeric(as.character(stab_df$Clusters))
stab_df
stab_measures
stab_only
stab_measures
stab_df
stab_df$Clusters
stab_df$Clusters
stab_measures <- slot(stab_only, "measures")
# Pasar el array [mÃ©todo, mÃ©trica, k] a data.frame largo
stab_df <- as.data.frame.table(stab_measures, responseName = "Score")
# Renombrar columnas para que sean mÃ¡s claras
colnames(stab_df) <- c("Method", "Measure", "Clusters", "Score")
stab_df$Clusters
as.character(stab_df$Clusters)
stab_df
# Extraer las mÃ©tricas de estabilidad
stab_measures <- slot(stab_only, "measures")
# Pasar el array [mÃ©todo, mÃ©trica, k] a data.frame largo
stab_df <- as.data.frame.table(stab_measures, responseName = "Score")
# Renombrar columnas para que sean mÃ¡s claras
colnames(stab_df) <- c("Method", "Measure", "Clusters", "Score")
# Aseguramos que 'Clusters' sea numÃ©rico
stab_df$Measure <- as.numeric(as.character(stab_df$Measure))
stab_df
# Ejemplo: ver las 10 combinaciones mÃ¡s estables segÃºn FOM
stab_df %>%
mutate(
APN = as.numeric(APN),
AD  = as.numeric(AD),
ADM = as.numeric(ADM),
FOM = as.numeric(FOM)
) %>%
arrange(FOM) %>%
head(10)
stab_df
stab_measures <- slot(stab_only, "measures")
# Pasar el array [mÃ©todo, mÃ©trica, k] a data.frame largo
stab_df <- as.data.frame.table(stab_measures, responseName = "Score")
# Renombrar columnas para que sean mÃ¡s claras
colnames(stab_df) <- c("Measure", "Method", "Clusters", "Score")
stab_df
# Extraer las mÃ©tricas de estabilidad
stab_measures <- slot(stab_only, "measures")
# Pasar el array [mÃ©todo, mÃ©trica, k] a data.frame largo
stab_df <- as.data.frame.table(stab_measures, responseName = "Score")
# Renombrar columnas para que sean mÃ¡s claras
colnames(stab_df) <- c("Measure", "Clusters", "Method", "Score")
# Aseguramos que 'Clusters' sea numÃ©rico
stab_df$Clusters <- as.numeric(as.character(stab_df$Clusters))
stab_df
# Ejemplo: ver las 10 combinaciones mÃ¡s estables segÃºn FOM
stab_df %>%
mutate(
APN = as.numeric(APN),
AD  = as.numeric(AD),
ADM = as.numeric(ADM),
FOM = as.numeric(FOM)
) %>%
arrange(FOM) %>%
head(10)
# Ejemplo: ver las 10 combinaciones mÃ¡s estables segÃºn FOM
stab_df %>%
filter(Measure == "FOM") %>%
arrange(Score) %>%
head(10)
internal_res <- clValid(
obj        = X_scaled,
nClust     = 2:8,
clMethods  = metodos,
validation = "internal",
maxitems   = 1500
)
summary(internal_res)
# Mejores combinaciones segÃºn cada Ã­ndice interno
optimalScores(internal_res)
# Mejores combinaciones segÃºn estabilidad
optimalScores(stab_only)
fviz_nbclust(X_scaled, kmeans, method = "wss") +
ggtitle("MÃ©todo del codo (WSS) - kmeans")
fviz_nbclust(X_scaled, kmeans, method = "silhouette") +
ggtitle("Silhouette medio - kmeans")
set.seed(123)
gap_km <- clusGap(X_scaled, FUN = kmeans, K.max = 10, B = 50)
fviz_gap_stat(gap_km) +
ggtitle("Gap statistic - kmeans")
# Mejores combinaciones segÃºn cada Ã­ndice interno
summary(internal_res)
# Mejores combinaciones segÃºn estabilidad
summary(stab_only)
# Distancia kNN para sugerir eps
kNNdistplot(X_scaled, k = 10)
abline(h = 1.5, col = "red", lty = 2)  # Ajustar a ojo segÃºn el grÃ¡fico
# Ajustar DBSCAN (ajusta eps segÃºn el grÃ¡fico anterior)
db_res <- dbscan(X_scaled, eps = 1.5, minPts = 10)
table(db_res$cluster)
# Silhouette solo para clusters > 0 (ruido = 0)
clusters_db <- db_res$cluster
valid_idx   <- clusters_db > 0
if (length(unique(clusters_db[valid_idx])) > 1) {
sil_db <- silhouette(clusters_db[valid_idx], dist(X_scaled[valid_idx, ]))
summary(sil_db)
plot(sil_db, border = NA, main = "Silhouette DBSCAN")
} else {
cat("DBSCAN no generÃ³ suficientes clusters vÃ¡lidos para calcular silhouette.\n")
}
k_final   <- 4
metodo_final <- "kmeans"  # "kmeans", "clara" o "hierarchical"
if (metodo_final == "kmeans") {
set.seed(123)
modelo_final <- kmeans(X_scaled, centers = k_final, nstart = 25)
clusters_final <- modelo_final$cluster
} else if (metodo_final == "clara") {
set.seed(123)
modelo_final <- clara(X_scaled, k = k_final)
clusters_final <- modelo_final$clustering
} else if (metodo_final == "hierarchical") {
d  <- dist(X_scaled)
hc <- hclust(d, method = "ward.D2")
clusters_final <- cutree(hc, k = k_final)
} else {
stop("MÃ©todo no soportado en este script.")
}
prospectos$cluster_final <- factor(clusters_final)
table(prospectos$cluster_final)
prospectos$cluster_final <- factor(clusters_final)
table(prospectos$cluster_final)
k_final   <- 4
metodo_final <- "kmeans"  # "kmeans", "clara" o "hierarchical"
if (metodo_final == "kmeans") {
set.seed(123)
modelo_final <- kmeans(X_scaled, centers = k_final, nstart = 25)
clusters_final <- modelo_final$cluster
} else if (metodo_final == "clara") {
set.seed(123)
modelo_final <- clara(X_scaled, k = k_final)
clusters_final <- modelo_final$clustering
} else if (metodo_final == "hierarchical") {
d  <- dist(X_scaled)
hc <- hclust(d, method = "ward.D2")
clusters_final <- cutree(hc, k = k_final)
} else {
stop("MÃ©todo no soportado en este script.")
}
prospectos$cluster_final <- factor(clusters_final)
table(prospectos$cluster_final)
k_final   <- 5
metodo_final <- "kmeans"  # "kmeans", "clara" o "hierarchical"
if (metodo_final == "kmeans") {
set.seed(123)
modelo_final <- kmeans(X_scaled, centers = k_final, nstart = 25)
clusters_final <- modelo_final$cluster
} else if (metodo_final == "clara") {
set.seed(123)
modelo_final <- clara(X_scaled, k = k_final)
clusters_final <- modelo_final$clustering
} else if (metodo_final == "hierarchical") {
d  <- dist(X_scaled)
hc <- hclust(d, method = "ward.D2")
clusters_final <- cutree(hc, k = k_final)
} else {
stop("MÃ©todo no soportado en este script.")
}
prospectos$cluster_final <- factor(clusters_final)
table(prospectos$cluster_final)
resumen_clusters <- prospectos %>%
group_by(cluster_final) %>%
summarise(
n                 = n(),
edad_media        = mean(edad),
ingresos_medios   = mean(ingresos_mensuales),
nivel_interes_med = mean(nivel_interes),
visitas_web_med   = mean(visitas_web),
open_rate_med     = mean(open_rate),
email_score_med   = mean(email_score),
tiempo_dec_med    = mean(tiempo_decision_dias)
)
resumen_clusters
pca_res <- prcomp(X_scaled, scale. = TRUE)
fviz_pca_ind(
pca_res,
geom.ind  = "point",
col.ind   = prospectos$cluster_final,
addEllipses = TRUE,
legend.title = "Cluster",
title = "PCA de prospectos coloreado por cluster final"
)
