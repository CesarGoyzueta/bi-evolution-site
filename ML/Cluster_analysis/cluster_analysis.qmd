---
title: "Segmentaci√≥n de prospectos y validaci√≥n de clusters"
author: "BI Evolution"
format:
  html:
    theme: darkly          # base dark
    toc: true
    toc-title: "Contenido"
    smooth-scroll: true
    self-contained: true
    page-layout: full
    grid:
      body-width: 1100px
      margin-width: 0px
      gutter-width: 1rem
execute:
  echo: false
  warning: false
  message: false
editor: visual
---

## 1. Preparaci√≥n del entorno

```{r}
#| echo: false
#| warning: false
#| message: false
# Instalar paquetes SOLO la primera vez, despu√©s puedes comentarlo
# install.packages(c("readr", "dplyr", "clValid", "cluster", "factoextra", "dbscan", "tibble"))

library(readr)
library(dplyr)
library(clValid)
library(cluster)
library(factoextra)
library(dbscan)
library(tibble)

set.seed(123)
```

## 2. Carga del dataset de prospectos

Se asume que el archivo `prospectos.csv` est√° en el mismo directorio que este Quarto.

```{r}
#| echo: false
#| warning: false
#| message: false
prospectos <- read_csv("C:/Users/Cesar/OneDrive/Proyectos futuros/BI_Evolution/ML/Cluster_analysis/prospectos.csv")

glimpse(prospectos)
```

## 3. Selecci√≥n de variables num√©ricas y estandarizaci√≥n

Seleccionamos solo variables num√©ricas para el clustering.
(Se pueden ajustar seg√∫n tu criterio de negocio.)

```{r}
#| echo: false
#| warning: false
#| message: false
vars_num <- c(
  "edad",
  "ingresos_mensuales",
  "nivel_interes",
  "tiempo_respuesta_min",
  "interacciones_previas",
  "visitas_web",
  "open_rate",
  "email_score",
  "tiempo_decision_dias"
)

X <- prospectos[, vars_num]

# Escalado (muy importante para clustering basado en distancia)
X_scaled <- scale(X)

summary(X_scaled)
```


## 4. Validaci√≥n de estabilidad con `clValid` (APN, AD, ADM, FOM)

En esta secci√≥n vamos a calcular medidas de **estabilidad del clustering**, evaluando qu√© tanto cambian los resultados cuando se elimina una variable del conjunto de datos.

Las m√©tricas consideradas son:

* **APN (Average Proportion of Non-overlap)**  
  Mide qu√© proporci√≥n de observaciones cambian de cluster cuando se elimina una variable.  
  **APN bajo ‚Üí clustering estable**.

* **AD (Average Distance)**  
  Mide cu√°nto cambian las distancias internas dentro de los clusters al remover una variable.  
  **AD bajo ‚Üí clusters robustos y compactos**.

* **ADM (Average Distance between Means)**  
  Mide cu√°nto se mueven los centros de los clusters al quitar una variable.  
  **ADM bajo ‚Üí clusters con estructura estable**.

* **FOM (Figure of Merit)**  
  Mide la variabilidad interna de la variable eliminada usando el clustering basado en las dem√°s.  
  **FOM bajo ‚Üí clusters m√°s coherentes**.

Se evaluar√°n los m√©todos:

* `kmeans`
* `clara`
* `hierarchical`
* `fanny`

para n√∫meros de clusters `k` entre 2 y 8.


```{r}
#| echo: false
#| warning: false
#| message: false
metodos <- c("kmeans", "clara", "hierarchical", "fanny")

stab_only <- clValid(
  obj        = X_scaled,
  nClust     = 2:8,
  clMethods  = metodos,
  validation = "stability",
  maxitems   = 1500
)

# Resumen general de estabilidad (APN, AD, ADM, FOM)
summary(stab_only)
```


### 4.1. Tabla de m√©tricas de estabilidad (APN, AD, ADM, FOM)
A continuaci√≥n extraemos las m√©tricas en un `data.frame` para analizarlas y ordenarlas por los valores m√°s bajos (m√°s estables).


```{r}
#| echo: false
#| warning: false
#| message: false
# Extraer las m√©tricas de estabilidad

stab_measures <- slot(stab_only, "measures")

# Pasar el array [m√©todo, m√©trica, k] a data.frame largo
stab_df <- as.data.frame.table(stab_measures, responseName = "Score")

# Renombrar columnas para que sean m√°s claras
colnames(stab_df) <- c("Measure", "Clusters", "Method", "Score")

# Aseguramos que 'Clusters' sea num√©rico
stab_df$Clusters <- as.numeric(as.character(stab_df$Clusters))


```

```{r}
# Ejemplo: ver las 10 combinaciones m√°s estables seg√∫n FOM
stab_df %>%
  filter(Measure == "FOM") %>% #APN,AD,ADM
  arrange(Score) %>%
  head(10)

```

---

## üìä Secci√≥n 5 ‚Äì Solo *internal validity* (silhouette, Dunn, etc.)

Aqu√≠ analizas **qu√© tan buenos** son los clusters desde el punto de vista interno (sin quitar variables), usando √≠ndices cl√°sicos de calidad de clustering.


## 5. Validaci√≥n interna con `clValid` (√≠ndices de calidad)

En esta secci√≥n evaluamos la **calidad interna** de los clusters usando √≠ndices cl√°sicos:

* **Silhouette width - Tiene m√°s peso dentro de las m√©tricas**  
  Mide qu√© tan similar es cada observaci√≥n a su propio cluster en comparaci√≥n con otros clusters.  
  Toma valores entre -1 y 1.  
  **Valores cercanos a 1 ‚Üí clusters bien separados y compactos.**

* **√çndice de Dunn**  
  Relaciona la distancia m√≠nima entre clusters con el di√°metro m√°ximo dentro de los clusters.Su valor es mayor a 0
  **Dunn alto ‚Üí clusters bien separados y poco dispersos.**

* **Connectivity**  
  Mide la medida en que observaciones cercanas en el espacio de caracter√≠sticas terminan en clusters distintos. Su valor es mayor a 0
  **Connectivity baja ‚Üí clustering m√°s ‚Äúnatural‚Äù seg√∫n la proximidad de los puntos.**

(Otros √≠ndices pueden aparecer en la salida de `clValid`, pero aqu√≠ nos centraremos en estos como referencia principal.)


```{r}
internal_res <- clValid(
  obj        = X_scaled,
  nClust     = 2:8,
  clMethods  = metodos,
  validation = "internal",
  maxitems   = 1500
)

summary(internal_res)
```


### 5.1. Selecci√≥n del mejor m√©todo y k seg√∫n √≠ndices internos

`clValid` tambi√©n resume cu√°l combinaci√≥n de m√©todo y n√∫mero de clusters optimiza cada √≠ndice.


```{r}
# Mejores combinaciones seg√∫n cada √≠ndice interno
summary(internal_res)

```

Y puedes cruzar con estabilidad:

```{r}
# Mejores combinaciones seg√∫n estabilidad
summary(stab_only)
```

> **Nota:** Estas salidas te dan una idea de qu√© m√©todo y k suelen ser mejores.

## 6. k √≥ptimo para k-means: elbow, silhouette y gap statistic

Aqu√≠ enfocamos solo en k-means para ilustrar los m√©todos cl√°sicos de selecci√≥n de k.

### 6.1. M√©todo del codo (WSS)

```{r}
fviz_nbclust(X_scaled, kmeans, method = "wss") +
  ggtitle("M√©todo del codo (WSS) - kmeans")
```

### 6.2. Silhouette medio

```{r}
fviz_nbclust(X_scaled, kmeans, method = "silhouette") +
  ggtitle("Silhouette medio - kmeans")
```

### 6.3. Gap statistic

```{r}
set.seed(123)
gap_km <- clusGap(X_scaled, FUN = kmeans, K.max = 10, B = 50)

fviz_gap_stat(gap_km) +
  ggtitle("Gap statistic - kmeans")
```

## 7. DBSCAN (extra, sin APN/AD/ADM/FOM)

DBSCAN no se presta igual a APN/AD/ADM/FOM porque no usa un k fijo.
Igual podemos explorarlo con silhouette y visualizaci√≥n.

```{r}
# Distancia kNN para sugerir eps
kNNdistplot(X_scaled, k = 10)
abline(h = 1.5, col = "red", lty = 2)  # Ajustar a ojo seg√∫n el gr√°fico
```

```{r}
# Ajustar DBSCAN (ajusta eps seg√∫n el gr√°fico anterior)
db_res <- dbscan(X_scaled, eps = 1.5, minPts = 10)

table(db_res$cluster)
```

```{r}
# Silhouette solo para clusters > 0 (ruido = 0)
clusters_db <- db_res$cluster
valid_idx   <- clusters_db > 0

if (length(unique(clusters_db[valid_idx])) > 1) {
  sil_db <- silhouette(clusters_db[valid_idx], dist(X_scaled[valid_idx, ]))
  summary(sil_db)
  plot(sil_db, border = NA, main = "Silhouette DBSCAN")
} else {
  cat("DBSCAN no gener√≥ suficientes clusters v√°lidos para calcular silhouette.\n")
}
```

## 8. Entrenamiento final con el m√©todo y k elegidos

En esta secci√≥n t√∫ eliges, a partir de las m√©tricas anteriores, el **m√©todo + k** que te parezca mejor.

Para el ejemplo, supongamos que elegimos:

* M√©todo: **kmeans**
* N√∫mero de clusters: **k = 4**

> Cambia estos valores seg√∫n lo que veas en las m√©tricas.

```{r}
k_final   <- 5
metodo_final <- "kmeans"  # "kmeans", "clara" o "hierarchical"
```

### 8.1. Ajuste seg√∫n el m√©todo elegido

```{r}
if (metodo_final == "kmeans") {
  set.seed(123)
  modelo_final <- kmeans(X_scaled, centers = k_final, nstart = 25)
  clusters_final <- modelo_final$cluster
  
} else if (metodo_final == "clara") {
  set.seed(123)
  modelo_final <- clara(X_scaled, k = k_final)
  clusters_final <- modelo_final$clustering
  
} else if (metodo_final == "hierarchical") {
  d  <- dist(X_scaled)
  hc <- hclust(d, method = "ward.D2")
  clusters_final <- cutree(hc, k = k_final)
  
} else {
  stop("M√©todo no soportado en este script.")
}

prospectos$cluster_final <- factor(clusters_final)
table(prospectos$cluster_final)
```

### 8.2. Resumen de perfiles por cluster

```{r}
resumen_clusters <- prospectos %>%
  group_by(cluster_final) %>%
  summarise(
    n                 = n(),
    edad_media        = mean(edad),
    ingresos_medios   = mean(ingresos_mensuales),
    nivel_interes_med = mean(nivel_interes),
    visitas_web_med   = mean(visitas_web),
    open_rate_med     = mean(open_rate),
    email_score_med   = mean(email_score),
    tiempo_dec_med    = mean(tiempo_decision_dias)
  )

resumen_clusters
```

## 9. Visualizaci√≥n final con PCA

Hacemos un PCA sobre las variables escaladas y coloreamos por `cluster_final`.

```{r}
pca_res <- prcomp(X_scaled, scale. = TRUE)

fviz_pca_ind(
  pca_res,
  geom.ind  = "point",
  col.ind   = prospectos$cluster_final,
  addEllipses = TRUE,
  legend.title = "Cluster",
  title = "PCA de prospectos coloreado por cluster final"
)
```

---

<!-- ## 10. Notas para llevar este resultado a Streamlit -->

<!-- * Desde este an√°lisis en R puedes decidir: -->

<!--   * Qu√© m√©todo usar (p.ej. kmeans) -->
<!--   * Con qu√© k (p.ej. 4) -->
<!-- * Luego puedes replicar **la misma l√≥gica** en Python: -->

<!--   * Escalar con `StandardScaler` -->
<!--   * Entrenar `KMeans(n_clusters = k)` -->
<!--   * Guardar `scaler` + modelo con `joblib` -->
<!--   * Cargar ambos en una app **Streamlit** para: -->

<!--     * Visualizar resumen de clusters -->
<!--     * Asignar cluster a nuevos prospectos -->
<!--     * Mostrar un PCA (hecho en Python) simil al de aqu√≠ -->

<!-- Este Quarto te sirve como **pieza ‚Äúcient√≠fica/t√©cnica‚Äù** de soporte para tu portafolio, -->
<!-- mientras que Streamlit ser√° la **pieza ‚Äúproducto/cliente‚Äù** que vas a mostrar. -->


